{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install omegaconf pandas scikit-learn torch fvcore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import omegaconf\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from tqdm.notebook import tqdm  # Use notebook-friendly tqdm\n",
    "\n",
    "# This import should now work because of the sys.path.append call in the previous cell\n",
    "from minigpt4.models.rec_model import MatrixFactorization\n",
    "\n",
    "def uAUC_me(user, predict, label):\n",
    "    if not isinstance(predict, np.ndarray):\n",
    "        predict = np.array(predict)\n",
    "    if not isinstance(label, np.ndarray):\n",
    "        label = np.array(label)\n",
    "    predict = predict.squeeze()\n",
    "    label = label.squeeze()\n",
    "\n",
    "    u, inverse, counts = np.unique(user, return_inverse=True, return_counts=True)  # sort in increasing\n",
    "    index = np.argsort(inverse)\n",
    "    candidates_dict = {}\n",
    "    k = 0\n",
    "    total_num = 0\n",
    "    only_one_interaction = 0\n",
    "    computed_u = []\n",
    "    for u_i in u:\n",
    "        start_id, end_id = total_num, total_num + counts[k]\n",
    "        u_i_counts = counts[k]\n",
    "        index_ui = index[start_id:end_id]\n",
    "        if u_i_counts == 1:\n",
    "            only_one_interaction += 1\n",
    "            total_num += counts[k]\n",
    "            k += 1\n",
    "            continue\n",
    "        candidates_dict[u_i] = [predict[index_ui], label[index_ui]]\n",
    "        total_num += counts[k]\n",
    "        k += 1\n",
    "    # print(f\"only one interaction users: {only_one_interaction}\")\n",
    "    auc = []\n",
    "    only_one_class = 0\n",
    "\n",
    "    for ui, pre_and_true in candidates_dict.items():\n",
    "        pre_i, label_i = pre_and_true\n",
    "        try:\n",
    "            ui_auc = roc_auc_score(label_i, pre_i)\n",
    "            auc.append(ui_auc)\n",
    "            computed_u.append(ui)\n",
    "        except:\n",
    "            only_one_class += 1\n",
    "\n",
    "    auc_for_user = np.array(auc)\n",
    "    # print(f\"computed user: {auc_for_user.shape[0]}, can not users: {only_one_class}\")\n",
    "    uauc = auc_for_user.mean()\n",
    "    # print(f\"uauc for validation Cost: {time.time() - start_time}, uauc: {uauc}\")\n",
    "    return uauc, computed_u, auc_for_user\n",
    "\n",
    "class early_stoper(object):\n",
    "    def __init__(self, ref_metric='valid_auc', incerase=True, patience=20) -> None:\n",
    "        self.ref_metric = ref_metric\n",
    "        self.best_metric = None\n",
    "        self.increase = incerase\n",
    "        self.reach_count = 0\n",
    "        self.patience = patience\n",
    "\n",
    "    def _registry(self, metrics):\n",
    "        self.best_metric = metrics\n",
    "\n",
    "    def update(self, metrics):\n",
    "        if self.best_metric is None:\n",
    "            self._registry(metrics)\n",
    "            return True\n",
    "        else:\n",
    "            if self.increase and metrics[self.ref_metric] > self.best_metric[self.ref_metric]:\n",
    "                self.best_metric = metrics\n",
    "                self.reach_count = 0\n",
    "                return True\n",
    "            elif not self.increase and metrics[self.ref_metric] < self.best_metric[self.ref_metric]:\n",
    "                self.best_metric = metrics\n",
    "                self.reach_count = 0\n",
    "                return True\n",
    "            else:\n",
    "                self.reach_count += 1\n",
    "                return False\n",
    "\n",
    "    def is_stop(self):\n",
    "        if self.reach_count >= self.patience:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "def run_a_trail(train_config, save_mode=False, save_file=None, need_train=True, warm_or_cold=None):\n",
    "    seed = 2023\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    data_dir = \"/content/CoRA/dataset/ml-1m/\"\n",
    "    train_data = pd.read_pickle(data_dir + \"train_ood2.pkl\")[['uid', 'iid', 'label']].values\n",
    "    valid_data = pd.read_pickle(data_dir + \"valid_ood2.pkl\")[['uid', 'iid', 'label']].values\n",
    "    test_data = pd.read_pickle(data_dir + \"test_ood2.pkl\")[['uid', 'iid', 'label']].values\n",
    "\n",
    "    user_num = max(train_data[:, 0].max(), valid_data[:, 0].max(), test_data[:, 0].max()) + 1\n",
    "    item_num = max(train_data[:, 1].max(), valid_data[:, 1].max(), test_data[:, 1].max()) + 1\n",
    "\n",
    "    print(f\"user nums: {user_num}, item nums: {item_num}\")\n",
    "\n",
    "    mf_config = {\n",
    "        \"user_num\": int(user_num),\n",
    "        \"item_num\": int(item_num),\n",
    "        \"embedding_size\": int(train_config['embedding_size'])\n",
    "    }\n",
    "    mf_config = omegaconf.OmegaConf.create(mf_config)\n",
    "\n",
    "    train_data_loader = DataLoader(train_data, batch_size=train_config['batch_size'], shuffle=True)\n",
    "    valid_data_loader = DataLoader(valid_data, batch_size=train_config['batch_size'], shuffle=False)\n",
    "    test_data_loader = DataLoader(test_data, batch_size=train_config['batch_size'], shuffle=False)\n",
    "\n",
    "    model = MatrixFactorization(mf_config).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=train_config['lr'], weight_decay=train_config['wd'])\n",
    "    early_stop = early_stoper(ref_metric='valid_auc', incerase=True, patience=train_config['patience'])\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    if not need_train:\n",
    "        model.load_state_dict(torch.load(save_file, map_location=device))\n",
    "        model.eval()\n",
    "        # ... (evaluation logic remains the same, just ensure data is moved to device)\n",
    "        return\n",
    "\n",
    "    for epoch in tqdm(range(train_config['epoch']), desc=\"Epochs\"):\n",
    "        model.train()\n",
    "        for bacth_id, batch_data in enumerate(tqdm(train_data_loader, desc=f\"Epoch {epoch+1} Training\", leave=False)):\n",
    "            batch_data = batch_data.to(device)\n",
    "            ui_matching = model(batch_data[:, 0].long(), batch_data[:, 1].long())\n",
    "            loss = criterion(ui_matching, batch_data[:, -1].float())\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        if epoch % train_config['eval_epoch'] == 0:\n",
    "            model.eval()\n",
    "            pre_val, label_val, users_val = [], [], []\n",
    "            with torch.no_grad():\n",
    "                for batch_data in tqdm(valid_data_loader, desc=f\"Epoch {epoch+1} Validation\", leave=False):\n",
    "                    batch_data = batch_data.to(device)\n",
    "                    ui_matching = model(batch_data[:, 0].long(), batch_data[:, 1].long())\n",
    "                    users_val.extend(batch_data[:, 0].cpu().numpy())\n",
    "                    pre_val.extend(ui_matching.cpu().numpy())\n",
    "                    label_val.extend(batch_data[:, -1].cpu().numpy())\n",
    "            valid_auc = roc_auc_score(label_val, pre_val)\n",
    "            valid_uauc, _, _ = uAUC_me(users_val, pre_val, label_val)\n",
    "\n",
    "            pre_test, label_test, users_test = [], [], []\n",
    "            with torch.no_grad():\n",
    "                for batch_data in tqdm(test_data_loader, desc=f\"Epoch {epoch+1} Testing\", leave=False):\n",
    "                    batch_data = batch_data.to(device)\n",
    "                    ui_matching = model(batch_data[:, 0].long(), batch_data[:, 1].long())\n",
    "                    users_test.extend(batch_data[:, 0].cpu().numpy())\n",
    "                    pre_test.extend(ui_matching.cpu().numpy())\n",
    "                    label_test.extend(batch_data[:, -1].cpu().numpy())\n",
    "            test_auc = roc_auc_score(label_test, pre_test)\n",
    "            test_uauc, _, _ = uAUC_me(users_test, pre_test, label_test)\n",
    "\n",
    "            updated = early_stop.update(\n",
    "                {'valid_auc': valid_auc, 'valid_uauc': valid_uauc, 'test_auc': test_auc, 'test_uauc': test_uauc, 'epoch': epoch}\n",
    "            )\n",
    "            if updated and save_mode:\n",
    "                torch.save(model.state_dict(), save_file)\n",
    "\n",
    "            print(f\"Epoch: {epoch+1}, Valid AUC: {valid_auc:.4f}, Valid uAUC: {valid_uauc:.4f}, Test AUC: {test_auc:.4f}, Test uAUC: {test_uauc:.4f}, Early Stop: {early_stop.reach_count}\")\n",
    "\n",
    "            if early_stop.is_stop():\n",
    "                print(\"Early stopping reached!\")\n",
    "                break\n",
    "\n",
    "    print(\"Training finished.\")\n",
    "    print(f\"Best result: {early_stop.best_metric}\")\n",
    "\n",
    "# --- Execution Block ---\n",
    "train_config = {\n",
    "    'lr': 1e-3,\n",
    "    'wd': 1e-4,\n",
    "    'embedding_size': 64,\n",
    "    \"epoch\": 100,\n",
    "    \"eval_epoch\": 1,\n",
    "    \"patience\": 10,\n",
    "    \"batch_size\": 1024\n",
    "}\n",
    "\n",
    "save_dir = \"/content/CoRA/pretrained/mf/\"\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "save_file = os.path.join(save_dir, \"mf_movielens_best.pth\")\n",
    "\n",
    "print(\"Starting training with config:\", train_config)\n",
    "print(f\"Model will be saved to: {save_file}\")\n",
    "\n",
    "run_a_trail(\n",
    "    train_config=train_config, \n",
    "    save_mode=True, \n",
    "    save_file=save_file,\n",
    "    need_train=True\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
